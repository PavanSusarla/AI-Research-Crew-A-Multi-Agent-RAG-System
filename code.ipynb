{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64fdfa-fcf2-42f1-8361-b1a0111afd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "# --- LangChain + OpenAI ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# --- CrewAI + Tools ---\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import tool\n",
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"mykey\"\n",
    "os.environ[\"SERPER_API_KEY\"] = \"mykey\"\n",
    "\n",
    "# Document Processor\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, embedding_model: str = \"text-embedding-ada-002\"):\n",
    "        self.embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "        self.vector_store = None\n",
    "    \n",
    "    def load_and_process(self, text_data: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> FAISS:\n",
    "        document = Document(page_content=text_data, metadata={\"source\": \"in-memory-text\"})\n",
    "        docs_list = [document]\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        docs = text_splitter.split_documents(docs_list)\n",
    "        self.vector_store = FAISS.from_documents(docs, self.embeddings)\n",
    "        return self.vector_store\n",
    "\n",
    "# RAG Tool\n",
    "class RAGTool:\n",
    "    def __init__(self, vector_store: FAISS):\n",
    "        self.retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    def retrieve(self, query: str) -> str:\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Webâ€search helper function\n",
    "def web_search(query: str) -> str:\n",
    "    url = f\"https://api.duckduckgo.com/?q={query}&format=json\"\n",
    "    response = requests.get(url).json()\n",
    "    results = response.get(\"RelatedTopics\", [])[:3]\n",
    "    return \"\\n\".join([r.get(\"Text\", \"\") for r in results if \"Text\" in r])\n",
    "\n",
    "# Memory setup (initially empty)\n",
    "memory = VectorStoreRetrieverMemory(\n",
    "    retriever=FAISS.from_texts([\"\"], OpenAIEmbeddings()).as_retriever()\n",
    ")\n",
    "\n",
    "# Agent definitions\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "planner_agent = Agent(\n",
    "    role=\"Query Decomposer\",\n",
    "    goal=\"Break down user queries into subtasks for research.\",\n",
    "    backstory=\"A strategic planner who organizes complex questions into manageable parts.\",\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "web_search_tool = SerperDevTool()\n",
    "\n",
    "research_agent = Agent(\n",
    "    role=\"Information Retriever\",\n",
    "    goal=\"Fetch relevant context using RAG and tools.\",\n",
    "    backstory=\"A diligent researcher with access to knowledge bases and web tools.\",\n",
    "    llm=llm,\n",
    "    tools=[web_search_tool],\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "analyzer_agent = Agent(\n",
    "    role=\"Content Synthesizer\",\n",
    "    goal=\"Synthesize retrieved data into a draft answer.\",\n",
    "    backstory=\"An analytical expert who creates coherent narratives from facts.\",\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "reviewer_agent = Agent(\n",
    "    role=\"Quality Assurer\",\n",
    "    goal=\"Evaluate and refine answers for accuracy and clarity.\",\n",
    "    backstory=\"A meticulous reviewer ensuring truthfulness and refinement.\",\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Task creation\n",
    "def create_tasks(user_query: str, rag_tool: RAGTool) -> List[Task]:\n",
    "    @tool(\"RAGRetriever\")\n",
    "    def rag_retrieve_tool(query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information from the document vector store.\"\"\"\n",
    "        return rag_tool.retrieve(query)\n",
    "    \n",
    "    # attach the tool to the research agent\n",
    "    research_agent.tools.append(rag_retrieve_tool)\n",
    "    \n",
    "    plan_task = Task(\n",
    "        description=f\"Break down the query: '{user_query}' into 2-3 subtasks.\",\n",
    "        agent=planner_agent,\n",
    "        expected_output=\"A list of 2-3 concise, actionable sub-queries/steps necessary to answer the user query.\",\n",
    "        memory=memory\n",
    "    )\n",
    "    research_task = Task(\n",
    "        description=\"Use RAG and web search to gather info based on planner's subtasks.\",\n",
    "        agent=research_agent,\n",
    "        context=[plan_task],\n",
    "        expected_output=\"A collection of relevant, verified research notes and snippets categorized by the subtasks.\",\n",
    "        memory=memory\n",
    "    )\n",
    "    analyze_task = Task(\n",
    "        description=\"Draft an answer synthesizing the retrieved context.\",\n",
    "        agent=analyzer_agent,\n",
    "        context=[research_task],\n",
    "        expected_output=\"A well-structured, easy-to-read draft answer to the user query, incorporating all gathered facts.\",\n",
    "        memory=memory\n",
    "    )\n",
    "    review_task = Task(\n",
    "        description=\"Evaluate the draft for accuracy and refine it.\",\n",
    "        agent=reviewer_agent,\n",
    "        context=[analyze_task],\n",
    "        expected_output=\"The final, polished answer to the user query, presented in clear paragraphs.\",\n",
    "        memory=memory\n",
    "    )\n",
    "    return [plan_task, research_task, analyze_task, review_task]\n",
    "\n",
    "# Runner\n",
    "def run_crew(user_query: str, vector_store: FAISS) -> str:\n",
    "    rag_tool = RAGTool(vector_store)\n",
    "    tasks = create_tasks(user_query, rag_tool)\n",
    "    crew = Crew(\n",
    "        agents=[planner_agent, research_agent, analyzer_agent, reviewer_agent],\n",
    "        tasks=tasks,\n",
    "        process=Process.sequential,\n",
    "        memory=True,\n",
    "        max_iterations=2,\n",
    "        max_execution_time=300\n",
    "    )\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Evaluation helper\n",
    "def evaluate_answer(query: str, answer: str, retrieved_docs: List[str]) -> Dict[str, float]:\n",
    "    query_words = set(query.lower().split())\n",
    "    answer_words = set(answer.lower().split())\n",
    "    relevance = len(query_words & answer_words) / len(query_words) if query_words else 0\n",
    "    accuracy = 1.0 if any(doc.lower() in answer.lower() for doc in retrieved_docs) else 0.5\n",
    "    coherence = 0.8\n",
    "    return {\"relevance\": relevance, \"accuracy\": accuracy, \"coherence\": coherence}\n",
    "\n",
    "# Demo usage\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\n",
    "    Artificial intelligence (AI) is intelligence demonstrated by machines. The term was coined in 1956. Early AI focused on symbolic reasoning. In the 1980s, expert systems emerged. The 21st century saw deep learning and neural networks. Key figures include Alan Turing and Geoffrey Hinton. AI applications include image recognition and natural language processing.\n",
    "    \"\"\"\n",
    "    processor = DocumentProcessor()\n",
    "    vector_store = processor.load_and_process(sample_text)\n",
    "    memory.retriever = vector_store.as_retriever()\n",
    "    \n",
    "    user_query = \"Explain the evolution of AI from the 1950s to now.\"\n",
    "    final_answer = run_crew(user_query, vector_store)\n",
    "    \n",
    "    rag_tool = RAGTool(vector_store)\n",
    "    retrieved = rag_tool.retrieve(user_query).split(\"\\n\")\n",
    "    scores = evaluate_answer(user_query, final_answer, retrieved)\n",
    "    \n",
    "    print(\"Final Answer:\", final_answer)\n",
    "    print(\"Evaluation Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e1170-6a79-4caf-a0b7-4d7a8871de6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
